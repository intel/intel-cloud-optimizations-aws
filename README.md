# Intel速 Cloud Optimization Modules for AWS

The Intel Cloud Optimization Modules (ICOMs) for AWS are open-source codebases with codified Intel AI software optimizations and instructions built specifically for AWS. The modules are designed to enable AI developers to maximize the performance and productivity of industry-leading Python machine learning and deep learning libraries on Intel hardware. Each module or reference architecture includes a complete instruction set and all source code published on GitHub. You can check out the full suite of Intel Cloud Optimization Modules [here](https://www.intel.com/content/www/us/en/developer/topic-technology/cloud-optimization.html). 

Here are the currently released modules for AWS:

- **[Intel速 Cloud Optimization Modules for AWS*: GPT2-Small Distributed Training](distributed-training/nlp)**: Fine-tune a Large Language Model (LLM) in a distributed setup on Intel Xeon CPUs.
- **[Intel速 Cloud Optimization Modules for AWS*: XGBoost* on Kubernetes*](kubernetes/xgboost)**: Build an accelerated Kubernetes cluster with Intel optimizations for XGBoost on an AWS computing cluster.
- **[Intel速 Cloud Optimization Modules for AWS*: XGBoost* on  SageMaker*](sagemaker/xgboost)**: Build an accelerated model development SageMaker pipeline and Lambda Inference Endpoint with Intel Optimizations for XGBoost.
